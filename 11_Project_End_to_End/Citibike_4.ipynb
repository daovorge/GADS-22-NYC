{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#4. Building a Predictive Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location = \"/Users/mrgholt/GADS-22-NYC/Citibike_Data/\"\n",
    "\n",
    "dfJanComplete = pd.read_csv(location + \"dfJanComplete.csv\")\n",
    "dfFebComplete = pd.read_csv(location + \"dfFebComplete.csv\")\n",
    "dfMarComplete = pd.read_csv(location + \"dfMarComplete.csv\")\n",
    "dfAprComplete = pd.read_csv(location + \"dfAprComplete.csv\")\n",
    "dfMayComplete = pd.read_csv(location + \"dfMayComplete.csv\")\n",
    "dfJunComplete = pd.read_csv(location + \"dfJunComplete.csv\")\n",
    "dfJulComplete = pd.read_csv(location + \"dfJulComplete.csv\")\n",
    "dfAugComplete = pd.read_csv(location + \"dfAugComplete.csv\")\n",
    "dfSepComplete = pd.read_csv(location + \"dfSepComplete.csv\")\n",
    "dfOctComplete = pd.read_csv(location + \"dfOctComplete.csv\")\n",
    "dfNovComplete = pd.read_csv(location + \"dfNovComplete.csv\")\n",
    "dfDecComplete = pd.read_csv(location + \"dfDecComplete.csv\")\n",
    "\n",
    "dfFebComplete = dfFebComplete[dfFebComplete.distance > 0.0]\n",
    "dfMarComplete = dfMarComplete[dfMarComplete.distance > 0.0]\n",
    "dfMayComplete = dfMayComplete[dfMayComplete.distance > 0.0]\n",
    "dfJunComplete = dfJunComplete[dfJunComplete.distance > 0.0]\n",
    "dfSepComplete = dfSepComplete[dfSepComplete.distance > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_speed(df, num):\n",
    "    speed_list = []\n",
    "    for i in xrange(num):\n",
    "        temp = df.iloc[i].tripduration/3600.0\n",
    "        speed = df.iloc[i].distance/temp\n",
    "        speed_list.append(speed)\n",
    "    return speed_list\n",
    "\n",
    "def calc_all_speeds(df):\n",
    "    df['speed'] = calculate_speed(df, len(df))\n",
    "    return df\n",
    "\n",
    "def get_outlier_thresholds(x):\n",
    "    lower_25 = x.quantile(0.25)\n",
    "    upper_75 = x.quantile(0.75)\n",
    "    high_threshold = upper_75 + 1.5 * (upper_75-lower_25)\n",
    "    low_threshold = lower_25 - 1.5 * (upper_75-lower_25)\n",
    "    return(low_threshold, high_threshold)\n",
    "\n",
    "def remove_outliers(x, low, high):\n",
    "    if x > high:\n",
    "        return np.nan\n",
    "    elif x < low:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def handle_outliers(df, column_name):\n",
    "    low_threshold, high_threshold = get_outlier_thresholds(df[column_name])     \n",
    "    new_column = df[column_name].map((lambda x: remove_outliers(x, low_threshold, high_threshold)))\n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_list = [dfJanComplete, dfFebComplete, dfMarComplete, dfAprComplete, dfMayComplete, dfJunComplete,\n",
    "             dfJulComplete, dfAugComplete, dfSepComplete, dfOctComplete, dfNovComplete, dfDecComplete] \n",
    "\n",
    "cols_f = ['tripduration', 'distance']\n",
    "\n",
    "for df in file_list:\n",
    "    for c in cols_f:\n",
    "        df[c] = handle_outliers(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_list = [dfJanComplete, dfFebComplete, dfMarComplete, dfAprComplete, dfMayComplete, dfJunComplete,\n",
    "             dfJulComplete, dfAugComplete, dfSepComplete, dfOctComplete, dfNovComplete, dfDecComplete] \n",
    "\n",
    "for df in file_list:\n",
    "    df = calc_all_speeds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = [dfJanComplete, dfFebComplete, dfMarComplete, dfAprComplete, dfMayComplete, dfJunComplete,\n",
    "             dfJulComplete, dfAugComplete, dfSepComplete, dfOctComplete, dfNovComplete, dfDecComplete] \n",
    "\n",
    "cols_f = ['speed']\n",
    "\n",
    "for df in file_list:\n",
    "    for c in cols_f:\n",
    "        df[c] = handle_outliers(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = [dfJanComplete, dfFebComplete, dfMarComplete, dfAprComplete, dfMayComplete, dfJunComplete,\n",
    "             dfJulComplete, dfAugComplete, dfSepComplete, dfOctComplete, dfNovComplete, dfDecComplete] \n",
    "\n",
    "cols_f = ['elev']\n",
    "\n",
    "for df in file_list:\n",
    "    for c in cols_f:\n",
    "        df[c] = handle_outliers(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll = dfJanComplete.copy()\n",
    "dfAll = dfAll.append(dfFebComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfMarComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfAprComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfMayComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfJunComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfJulComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfAugComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfSepComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfOctComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfNovComplete, ignore_index = True)\n",
    "dfAll = dfAll.append(dfDecComplete, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfAll = dfAll.dropna()\n",
    "dfAll = dfAll.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7663 entries, 0 to 7662\n",
      "Data columns (total 36 columns):\n",
      "index                      7663 non-null int64\n",
      "Unnamed: 0                 7663 non-null int64\n",
      "day                        7663 non-null object\n",
      "tripduration               7663 non-null float64\n",
      "starttime                  7663 non-null object\n",
      "stoptime                   7663 non-null object\n",
      "start.station.id           7663 non-null int64\n",
      "start.station.name         7663 non-null object\n",
      "start.station.latitude     7663 non-null float64\n",
      "start.station.longitude    7663 non-null float64\n",
      "end.station.id             7663 non-null int64\n",
      "end.station.name           7663 non-null object\n",
      "end.station.latitude       7663 non-null float64\n",
      "end.station.longitude      7663 non-null float64\n",
      "bikeid                     7663 non-null int64\n",
      "usertype                   7663 non-null object\n",
      "birth.year                 7663 non-null int64\n",
      "gender                     7663 non-null int64\n",
      "distance                   7663 non-null float64\n",
      "zip                        7663 non-null object\n",
      "elev                       7663 non-null float64\n",
      "dew                        7663 non-null float64\n",
      "precip                     7663 non-null float64\n",
      "hum                        7663 non-null int64\n",
      "snow                       7663 non-null int64\n",
      "temp                       7663 non-null float64\n",
      "windspeed                  7663 non-null float64\n",
      "visibility                 7663 non-null float64\n",
      "windchill                  7663 non-null float64\n",
      "heatindex                  7663 non-null float64\n",
      "fog                        7663 non-null int64\n",
      "rain                       7663 non-null int64\n",
      "hail                       7663 non-null int64\n",
      "thunder                    7663 non-null int64\n",
      "tornado                    7663 non-null int64\n",
      "speed                      7663 non-null float64\n",
      "dtypes: float64(15), int64(14), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dfAll.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfAll.speed = dfAll.speed.astype(float)\n",
    "dfAll.temp = dfAll.temp.astype(float)\n",
    "dfAll.elev = dfAll.elev.astype(float)\n",
    "dfAll.windspeed = dfAll.windspeed.astype(float)\n",
    "dfAll.windchill = dfAll.windchill.astype(float)\n",
    "dfAll.hum = dfAll.hum.astype(float)\n",
    "dfAll.precip = dfAll.precip.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll['logspeed'] = np.log10(dfAll.speed.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfres = dfAll[['logspeed', 'speed', 'temp', 'elev', 'windspeed', 'windchill', 'hum', 'precip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 'elev', 'windspeed', 'windchill', 'hum', 'precip']\n"
     ]
    }
   ],
   "source": [
    "predictors = list(dfres.columns.values)\n",
    "predictors.remove('speed')\n",
    "predictors.remove('logspeed')\n",
    "print predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logspeed</th>\n",
       "      <th>speed</th>\n",
       "      <th>temp</th>\n",
       "      <th>elev</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>windchill</th>\n",
       "      <th>hum</th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0.336404</td>\n",
       "      <td> 0.234902</td>\n",
       "      <td>-0.611591</td>\n",
       "      <td> 0.054319</td>\n",
       "      <td>-3.009389</td>\n",
       "      <td>-0.59203</td>\n",
       "      <td>-0.416958</td>\n",
       "      <td>-0.237757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1.100526</td>\n",
       "      <td> 1.077496</td>\n",
       "      <td>-0.611591</td>\n",
       "      <td> 1.201926</td>\n",
       "      <td>-3.009389</td>\n",
       "      <td>-0.59203</td>\n",
       "      <td> 1.295829</td>\n",
       "      <td>-0.237757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1.397968</td>\n",
       "      <td> 1.441758</td>\n",
       "      <td>-0.611591</td>\n",
       "      <td> 0.054319</td>\n",
       "      <td>-3.009389</td>\n",
       "      <td>-0.59203</td>\n",
       "      <td> 0.724900</td>\n",
       "      <td>-0.237757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.758000</td>\n",
       "      <td>-0.769010</td>\n",
       "      <td>-0.489687</td>\n",
       "      <td> 0.729382</td>\n",
       "      <td> 0.331595</td>\n",
       "      <td>-0.59203</td>\n",
       "      <td> 1.695479</td>\n",
       "      <td> 4.205975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1.226725</td>\n",
       "      <td> 1.229414</td>\n",
       "      <td>-0.706993</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>-3.009389</td>\n",
       "      <td>-0.59203</td>\n",
       "      <td> 1.581294</td>\n",
       "      <td>-0.237757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logspeed     speed      temp      elev  windspeed  windchill       hum  \\\n",
       "0  0.336404  0.234902 -0.611591  0.054319  -3.009389   -0.59203 -0.416958   \n",
       "1  1.100526  1.077496 -0.611591  1.201926  -3.009389   -0.59203  1.295829   \n",
       "2  1.397968  1.441758 -0.611591  0.054319  -3.009389   -0.59203  0.724900   \n",
       "3 -0.758000 -0.769010 -0.489687  0.729382   0.331595   -0.59203  1.695479   \n",
       "4  1.226725  1.229414 -0.706993 -0.013188  -3.009389   -0.59203  1.581294   \n",
       "\n",
       "     precip  \n",
       "0 -0.237757  \n",
       "1 -0.237757  \n",
       "2 -0.237757  \n",
       "3  4.205975  \n",
       "4 -0.237757  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit(dfres)\n",
    "dfres_scaled = pd.DataFrame(scaler.transform(dfres), columns = dfres.columns)\n",
    "dfres_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brute_force(data, target_variable, predictors, model, alpha_list = [1.0], degree_list = [3]):\n",
    "    ''' brute_force is a simple function designed to:\n",
    "    test every combination of predictors submitted in the predictors argument\n",
    "    test all degrees of polynomial as submitted in the degree_list argument\n",
    "    test a number of regularization parameters as submitted in the alpha_list argument\n",
    "    \n",
    "    model is the algorithm to be tested\n",
    "     '''\n",
    "    min_mse = 1e99\n",
    "    test_size_split = 0.5\n",
    "\n",
    "    #search over every combination of the predictors - using the itertools functionality\n",
    "    for i in xrange(1, 5):\n",
    "        \n",
    "        #build and test a model for each combination of predictors\n",
    "        for j in combinations(predictors, i):\n",
    "            \n",
    "            test_predictors = list(j)\n",
    "            \n",
    "            #use train test split to get the training and test datasets, according to the parameter test_size_split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data[test_predictors], \\\n",
    "                                                    data[target_variable], test_size=test_size_split, random_state=42)\n",
    "            \n",
    "            #Now search over all the polynomial degrees in the degree_list\n",
    "            for degree in degree_list:\n",
    "                \n",
    "                #Make sure each model is regularized, and search over all alphas in the regularization list\n",
    "                for a in alpha_list:\n",
    "                    \n",
    "                    #build the model\n",
    "                    clf = make_pipeline(PolynomialFeatures(degree), model(alpha = a, max_iter = 5000))\n",
    "                    \n",
    "                    #fit the model\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    \n",
    "                    #Get the test set predictions\n",
    "                    y_hat = clf.predict(X_test)\n",
    "                    \n",
    "                    #measure the mean squared error of the test set\n",
    "                    mse = mean_squared_error(y_hat, y_test)\n",
    "                    \n",
    "                    #remember ALL information for the minimum\n",
    "                    if mse < min_mse:\n",
    "                        min_mse = mse\n",
    "                        min_clf = clf\n",
    "                        min_predictors = test_predictors\n",
    "                        min_degree = degree\n",
    "                        min_alpha = a\n",
    "                        #unless you cannot afford to do this, it is always a good idea to remember the train, test\n",
    "                        #datasets actually used to build your model\n",
    "                        min_X_train = X_train\n",
    "                        min_y_train = y_train\n",
    "                        min_X_test = X_test\n",
    "                        min_y_test = y_test\n",
    "                    \n",
    "    #return a tuple for the minimum model and parameters\n",
    "    return (min_mse, min_clf, min_predictors, min_degree, min_alpha, min_X_train, min_y_train, min_X_test, min_y_test)\n",
    "\n",
    "def print_essential_results(results):\n",
    "    print \"MSE = {:5.7f}\".format(results[0])\n",
    "    print \"Best predictors = \", results[2]\n",
    "    print \"Optimal degree polynomial = \", results[3]\n",
    "    print \"Optimal regularization value = \", results[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_results = brute_force(dfres_scaled, \n",
    "                        'speed', \n",
    "                        predictors, \n",
    "                        Lasso, \n",
    "                        alpha_list=np.logspace(-5, 1, 5), \n",
    "                        degree_list = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9628376\n",
      "Best predictors =  ['temp', 'elev']\n",
      "Optimal degree polynomial =  2\n",
      "Optimal regularization value =  1e-05\n"
     ]
    }
   ],
   "source": [
    "print_essential_results(lasso_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_results = brute_force(dfres_scaled, \n",
    "                        'logspeed', \n",
    "                        predictors, \n",
    "                        Lasso, \n",
    "                        alpha_list=np.logspace(-5, 1, 5), \n",
    "                        degree_list = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9535393\n",
      "Best predictors =  ['temp', 'elev']\n",
      "Optimal degree polynomial =  2\n",
      "Optimal regularization value =  1e-05\n"
     ]
    }
   ],
   "source": [
    "print_essential_results(lasso_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Using the Model to Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_speed(temp, elev, scaler, dfres, results):\n",
    "    X1 = np.array([0.0, 0.0, temp, elev, 0.0, 0.0, 0.0, 0.0])\n",
    "    X1 = scaler.transform(X1)\n",
    "    X1 = X1[2:4]\n",
    "    X1 = X1.reshape(1, X1.shape[0])\n",
    "    clf = results[1]\n",
    "    y = clf.predict(X1)    \n",
    "    y_hat = np.array([y, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    logy = scaler.inverse_transform(y_hat)\n",
    "    return np.power(10.0, logy[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your initial speed at temp 35 deg F and elevation 50.00 is 10.29 mph\n",
      "Your subsequent speed at temp 75 deg F and elevation 50.00 is 10.88 mph\n",
      "Your initial journey of 3.92 miles will take 22.86 minutes\n",
      "Your subsequent journey of 3.92 miles will take 21.61 minutes\n",
      "Your journey differential is 74.60 seconds\n"
     ]
    }
   ],
   "source": [
    "temp_start = 35.0\n",
    "elev_start = 50.0\n",
    "\n",
    "temp_next = 75\n",
    "elev_next = 50.0\n",
    "\n",
    "distance_to_travel = 3.92 \n",
    "\n",
    "yhat_1 = calc_speed(temp_start, elev_start, scaler, dfres, lasso_results)\n",
    "yhat_2 = calc_speed(temp_next, elev_next, scaler, dfres, lasso_results)\n",
    "\n",
    "time_start = distance_to_travel/yhat_1\n",
    "time_next = distance_to_travel/yhat_2\n",
    "\n",
    "print \"Your initial speed at temp {:2.0f} deg F and elevation {:5.2f} is {:5.2f} mph\".format(temp_start, elev_start, yhat_1)\n",
    "print \"Your subsequent speed at temp {:2.0f} deg F and elevation {:5.2f} is {:5.2f} mph\".format(temp_next, elev_next, yhat_2)\n",
    "\n",
    "print \"Your initial journey of {:4.2f} miles will take {:5.2f} minutes\".format(distance_to_travel, time_start*60.0)\n",
    "print \"Your subsequent journey of {:4.2f} miles will take {:5.2f} minutes\".format(distance_to_travel, time_next*60.0)\n",
    "\n",
    "print \"Your journey differential is {:5.2f} seconds\".format(np.fabs(((time_start * 60.0)-(time_next * 60.0)) * 60.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
