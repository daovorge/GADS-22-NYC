{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Naives Bayes for Continuous Features\n",
    "=====\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##$$f(x_{i}\\text{ }|\\text{ }y) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}_{y}}}\\text{exp}\\left(-\\frac{\\left(x_{i}-\\mu_{y}\\right)^{2}}{2\\sigma^{2}_{y}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each feature within each class you calculate a mean and a variance $\\mu_{y}\\text{ and }\\sigma_{y}$\n",
    "- for each example you calculate the probability with respect to the mean and variance of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Consider the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_means_and_variances(iris):\n",
    "    '''This calculates the means and the variances by feature and by class.\n",
    "    For each feature we calculate the mean and the variance separately for each class.\n",
    "    There are 4 features and 3 classes'''\n",
    "\n",
    "    means = []\n",
    "    varis = []\n",
    "    for feature in [0, 1, 2, 3]:\n",
    "        for cls in [0, 1, 2]:\n",
    "            \n",
    "            #Separate the data by class and feature\n",
    "            f1 = np.array(iris.data[iris.target==cls, feature])\n",
    "            \n",
    "            #append the mean and variance to the two accumulator lists\n",
    "            means.append(f1.mean())\n",
    "            varis.append(f1.std()*f1.std())\n",
    "            \n",
    "    return (means, varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mv = get_means_and_variances(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_L(iris, n, mv):\n",
    "    '''Using our lists of the means and variances we take a record, n, and estimate the probability, using the\n",
    "    Gaussian distribution formula for each of the features within the record\n",
    "    The probabilities for the features are calculated against each class mean and each class variance'''\n",
    "    \n",
    "    #the overall results accumulator list\n",
    "    res = []\n",
    "    for i, feature in enumerate(iris.data[n]):\n",
    "        \n",
    "        #class accumulator list for each feature in the feature vector\n",
    "        res_in = []\n",
    "        for j, cls in enumerate([0, 1, 2]):\n",
    "            \n",
    "            #get the correct index to find the correct mean and variance\n",
    "            index = i * 3 + j\n",
    "            \n",
    "            #calculate the Guassian\n",
    "            #mv[0] are the means, mv[1] are the variances\n",
    "            p = (1.0/np.sqrt(2.0*np.pi*mv[1][index]))*\\\n",
    "            np.exp(-((feature - mv[0][index])*(feature - mv[0][index]))/(2.0*mv[1][index]))\n",
    "            \n",
    "            #accumulate the results for the feature with the 3 classes\n",
    "            res_in.append(p)\n",
    "            \n",
    "        #put one list into another to return a list of lists\n",
    "        res.append(res_in)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_res(res):\n",
    "    '''A function to pretty print the results'''\n",
    "    \n",
    "    #For each feature print out the class probabilities for the 3 classes\n",
    "    for i in [0, 1, 2, 3]:\n",
    "        print '\\n\\nfeature {:d}'.format(i+1)\n",
    "        for j in [0, 1, 2]:\n",
    "            print 'class {:d} = {:5.2f}'.format(j, res[i][j]),\n",
    "            \n",
    "    #Now sum BY CLASS - p(x1|C1)*p(x2|C1)*p(x3|C1)\n",
    "    #repeat for C1, C2, and C3\n",
    "    print \"\\n\\n\"\n",
    "    for j in [0, 1, 2]:\n",
    "        pres = 1.0\n",
    "        for i in [0, 1, 2, 3]:\n",
    "            pres *= res[i][j]\n",
    "        print 'class {:d} = {:5.5f}'.format(j, pres),\n",
    "    #the biggest magnitude wins the classification\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "feature 1\n",
      "class 0 =  1.09 class 1 =  0.10 class 2 =  0.02 \n",
      "\n",
      "feature 2\n",
      "class 0 =  0.57 class 1 =  0.98 class 2 =  1.25 \n",
      "\n",
      "feature 3\n",
      "class 0 =  2.17 class 1 =  0.00 class 2 =  0.00 \n",
      "\n",
      "feature 4\n",
      "class 0 =  3.45 class 1 =  0.00 class 2 =  0.00 \n",
      "\n",
      "\n",
      "class 0 = 4.67037 class 1 = 0.00000 class 2 = 0.00000\n"
     ]
    }
   ],
   "source": [
    "#The first record belong to class 1\n",
    "print iris.target[1]\n",
    "res = calculate_L(iris, 1, mv)\n",
    "print_res(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "feature 1\n",
      "class 0 =  0.00 class 1 =  0.52 class 2 =  0.61 \n",
      "\n",
      "feature 2\n",
      "class 0 =  0.89 class 1 =  0.49 class 2 =  0.97 \n",
      "\n",
      "feature 3\n",
      "class 0 =  0.00 class 1 =  0.75 class 2 =  0.11 \n",
      "\n",
      "feature 4\n",
      "class 0 =  0.00 class 1 =  1.37 class 2 =  0.23 \n",
      "\n",
      "\n",
      "class 0 = 0.00000 class 1 = 0.26251 class 2 = 0.01523\n"
     ]
    }
   ],
   "source": [
    "#The fifty first record belong to class 2\n",
    "print iris.target[51]\n",
    "res = calculate_L(iris, 51, mv)\n",
    "print_res(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "\n",
      "feature 1\n",
      "class 0 =  0.09 class 1 =  0.75 class 2 =  0.29 \n",
      "\n",
      "feature 2\n",
      "class 0 =  0.17 class 1 =  1.25 class 2 =  0.86 \n",
      "\n",
      "feature 3\n",
      "class 0 =  0.00 class 1 =  0.17 class 2 =  0.52 \n",
      "\n",
      "feature 4\n",
      "class 0 =  0.00 class 1 =  0.03 class 2 =  1.32 \n",
      "\n",
      "\n",
      "class 0 = 0.00000 class 1 = 0.00439 class 2 = 0.17107\n"
     ]
    }
   ],
   "source": [
    "#The one hundred and first record belong to class 2\n",
    "print iris.target[101]\n",
    "res = calculate_L(iris, 101, mv)\n",
    "print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Now use the sklearn routine and run a quick classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.5, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2\n",
       "Actual               \n",
       "0          27   0   0\n",
       "1           0  22   1\n",
       "2           0   3  22"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Question\n",
    "===\n",
    "1. What advantages do you notice in building the above classifier compared with building parameteric model classifiers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
