{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import urllib2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Revisiting the Baseball Dataset with Support Vector Machines\n",
    "=====\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####A whole bunch of pre-processing we have already seen in the Baseball Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mrgholt/GADS-22-NYC/Datasets/Hitters.csv')\n",
    "df.dropna(inplace = True)\n",
    "df.League = pd.factorize(df.League)[0]\n",
    "df.Division = pd.factorize(df.Division)[0]\n",
    "df.NewLeague = pd.factorize(df.NewLeague)[0]\n",
    "predictors = list(df.columns.values)\n",
    "predictors.remove('Salary')\n",
    "scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit(df)\n",
    "df_scaled = pd.DataFrame(scaler.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##A brute force approach\n",
    "###But limit the number of features for which we produce combinations for!!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Introduce a new parameter 'max_num_features_to_try', so as to limit the number of features this function will\n",
    "#use as a argument into combinations\n",
    "\n",
    "def brute_force(data, target_variable, predictors, model, alpha_list = [1.0], degree_list = [3],\n",
    "                max_num_features_to_try = 3):\n",
    "    ''' brute_force is a simple function designed to:\n",
    "    test every combination of predictors submitted in the predictors argument\n",
    "    test all degrees of polynomial as submitted in the degree_list argument\n",
    "    test a number of regularization parameters as submitted in the alpha_list argument\n",
    "    \n",
    "    model is the algorithm to be tested\n",
    "     '''\n",
    "    min_mse = 1e99\n",
    "    test_size_split = 0.5\n",
    "\n",
    "    #search over every combination of the predictors - using the itertools functionality\n",
    "    for i in xrange(1, max_num_features_to_try + 1):\n",
    "        #it's not a bad idea to put an indicator of progress into the code\n",
    "        print '.',\n",
    "        \n",
    "        #build and test a model for each combination of predictors\n",
    "        for j in combinations(predictors, i):\n",
    "            \n",
    "            test_predictors = list(j)\n",
    "            \n",
    "            #use train test split to get the training and test datasets, according to the parameter test_size_split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data[test_predictors], \\\n",
    "                                                    data[target_variable], test_size=test_size_split, random_state=42)\n",
    "            \n",
    "            #Now search over all the polynomial degrees in the degree_list\n",
    "            for degree in degree_list:\n",
    "                \n",
    "                #Make sure each model is regularized, and search over all alphas in the regularization list\n",
    "                for a in alpha_list:\n",
    "                    \n",
    "                    #build the model - all parameteres being determined using the training data\n",
    "                    clf = make_pipeline(PolynomialFeatures(degree), model(alpha = a))\n",
    "                    dummy = PolynomialFeatures(degree).fit_transform(X_train)\n",
    "                    \n",
    "                    #fit the model\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    \n",
    "                    #Get the test set predictions\n",
    "                    y_hat = clf.predict(X_test)\n",
    "                    \n",
    "                    #measure the mean squared error of the test set\n",
    "                    mse = mean_squared_error(y_hat, y_test)\n",
    "                    \n",
    "                    #remember ALL information for the minimum\n",
    "                    if mse < min_mse:\n",
    "                        min_mse = mse\n",
    "                        min_clf = clf\n",
    "                        min_predictors = test_predictors\n",
    "                        min_degree = degree\n",
    "                        min_alpha = a\n",
    "                        #unless you cannot afford to do this, it is always a good idea to remember the train, test\n",
    "                        #datasets actually used to build your model\n",
    "                        min_X_train = X_train\n",
    "                        min_y_train = y_train\n",
    "                        min_X_test = X_test\n",
    "                        min_y_test = y_test\n",
    "                        input_dimension = dummy.shape[1]\n",
    "                    \n",
    "    #return a tuple for the minimum model and parameters\n",
    "    return (min_mse, min_clf, min_predictors, min_degree, min_alpha, \n",
    "            min_X_train, min_y_train, min_X_test, min_y_test, input_dimension)\n",
    "\n",
    "def print_essential_results(results):\n",
    "    print \"MSE = {:5.7f}\".format(results[0])\n",
    "    print \"Best predictors = \", results[2]\n",
    "    print \"Input dimension = \", results[9]\n",
    "    print \"Optimal degree polynomial = \", results[3]\n",
    "    print \"Optimal regularization value = \", results[4]\n",
    "\n",
    "def get_degree_v_mse(results, model, degree_list=[3], ylog=1.0, ylim_low = 0.0, ylim_high=1.0):\n",
    "    '''get_degree_v_mse uses the results list to produce a plot of degree vs mse for the training\n",
    "    and test sets'''\n",
    "    \n",
    "    #use the regularization parameter you found in the brute force routine\n",
    "    model_alpha = results[4]\n",
    "\n",
    "    #set up the lists to accumulate the MSE's\n",
    "    training_error = []\n",
    "    testing_error = []\n",
    "    \n",
    "    #Search through each degree in the supplied degree_list\n",
    "    for degree in degree_list:\n",
    "        \n",
    "        #Build the model\n",
    "        clf = make_pipeline(PolynomialFeatures(degree), model())\n",
    "        \n",
    "        #Fit the model using the training data from the brute force routine\n",
    "        clf.fit(results[5], results[6])\n",
    "        \n",
    "        #Accumulate the mse results for the training and test sets\n",
    "        training_error.append(mean_squared_error(results[6], clf.predict(results[5])))\n",
    "        testing_error.append(mean_squared_error(results[8], clf.predict(results[7])))\n",
    "    \n",
    "    #Plot the results\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(np.array(degree_list), np.array(training_error), color = 'green', marker = 'o', label='Training Error')\n",
    "    ax.plot(np.array(degree_list), np.array(testing_error), color = 'red', marker = 'o', label='Validation Error')\n",
    "    ax.set_title(\"PLot of MSE vs Poylnomial Degree\")\n",
    "    if ylog:\n",
    "        ax.set_yscale('Log')\n",
    "        ax.set_ylabel('Log(MSE)')\n",
    "    else:\n",
    "        ax.set_ylabel('MSE')\n",
    "\n",
    "    ax.set_ylim(ylim_low, ylim_high)\n",
    "    ax.set_xlabel('Degree')\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "def get_alpha_v_mse(results, model, alpha_list=[0.1], ylog=1.0, ylim_low = 0.0,ylim_high=1.0):\n",
    "    '''get_alpha_v_mse uses the results list to produce a plot of regularization vs mse for the training\n",
    "    and test sets'''\n",
    "    \n",
    "    #use the polynomial degree you found in the brute force routine\n",
    "    max_degree = results[3]\n",
    "\n",
    "    #set up the lists to accumulate the MSE's\n",
    "    training_error = []\n",
    "    testing_error = []\n",
    "    \n",
    "    #Search through each regularization parameter in the supplied alpha_list\n",
    "    for a in alpha_list:\n",
    "        \n",
    "        #build the model\n",
    "        clf = make_pipeline(PolynomialFeatures(max_degree), model(alpha=a))\n",
    "        \n",
    "        #fit the model using the training set used in the brute force routine\n",
    "        clf.fit(results[5], results[6])\n",
    "        \n",
    "        #accumulate the mse for the training and test sets\n",
    "        training_error.append(mean_squared_error(results[6], clf.predict(results[5])))\n",
    "        testing_error.append(mean_squared_error(results[8], clf.predict(results[7])))\n",
    "    \n",
    "    \n",
    "    #plot the results\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(np.array(alpha_list), np.array(training_error), color = 'green', marker = 'o', label='Training Error')\n",
    "    ax.plot(np.array(alpha_list), np.array(testing_error), color = 'red', marker = 'o', label='Validation Error')\n",
    "    ax.set_title(\"PLot of Regularization vs Poylnomial Degree\")\n",
    "    if ylog:\n",
    "        ax.set_yscale('Log')\n",
    "        ax.set_ylabel('Log(MSE)')\n",
    "    else:\n",
    "        ax.set_ylabel('MSE')\n",
    "\n",
    "    ax.set_ylim(ylim_low, ylim_high)\n",
    "    ax.set_xscale('Log')\n",
    "    ax.set_xlabel('Log Alpha')\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "def plot_results(results):\n",
    "    '''plots out the the y_test predictions (y_hat) vs the actual, known results'''\n",
    "    \n",
    "    mpl.style.use('ggplot')\n",
    "    half_points = len(results[8])/2\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax = plt.subplot(311)\n",
    "    ax.plot(results[8][:half_points], color = 'blue', marker='o')\n",
    "    ax.plot(results[1].predict(results[7])[:half_points], color=\"red\", marker='o')\n",
    "    \n",
    "    ax = plt.subplot(312)\n",
    "    ax.plot(results[8][half_points:], color = 'blue', marker='o')\n",
    "    ax.plot(results[1].predict(results[7])[half_points:], color=\"red\", marker='o')\n",
    "    \n",
    "    max_points_to_display = 100\n",
    "    yy = np.ones(len(results[8]))\n",
    "    thigh = results[1].predict(results[7]) + (yy * np.sqrt(results[0]))\n",
    "    tlow = results[1].predict(results[7]) - (yy * np.sqrt(results[0]))\n",
    "    x_plot = np.arange(0, len(results[8]))\n",
    "\n",
    "    ax = plt.subplot(313)\n",
    "    ax.plot(results[8][:max_points_to_display], color = 'blue', marker='.')\n",
    "    ax.plot(results[1].predict(results[7])[:max_points_to_display], color=\"red\", marker='.', alpha=0.35)\n",
    "    ax.fill_between(x_plot[:max_points_to_display], thigh[:max_points_to_display],\\\n",
    "                tlow[:max_points_to_display], color='k', alpha=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-10,   3.59381366e-09,   1.29154967e-07,\n",
       "         4.64158883e-06,   1.66810054e-04,   5.99484250e-03,\n",
       "         2.15443469e-01,   7.74263683e+00,   2.78255940e+02,\n",
       "         1.00000000e+04])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-10,4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Try Ridge\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .\n"
     ]
    }
   ],
   "source": [
    "#Let's call out brute force function and see if we can find a good model\n",
    "#This may take an hour or two to run with the parameters below!\n",
    "#ridge_results = brute_force(df_scaled, \n",
    "#                        'Salary', \n",
    "#                        predictors, \n",
    "#                        Ridge, \n",
    "#                        alpha_list=np.logspace(-10, 4, 10), \n",
    "#                        degree_list = [2, 3, 4],\n",
    "#                        max_num_features_to_try = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.3729795\n",
      "Best predictors =  ['AtBat', 'Walks', 'Years', 'CRBI', 'NewLeague']\n",
      "Input dimension =  126\n",
      "Optimal degree polynomial =  4\n",
      "Optimal regularization value =  7.74263682681\n"
     ]
    }
   ],
   "source": [
    "#print_essential_results(ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.851834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td> 0.851834</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual  predicted\n",
       "actual     1.000000   0.851834\n",
       "predicted  0.851834   1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'actual' : ridge_results[8], 'predicted' : ridge_results[1].predict(ridge_results[7])}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Try Lasso\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . .\n"
     ]
    }
   ],
   "source": [
    "#Let's call out brute force function and see if we can find a good model\n",
    "#This may take an hour or two to run with the parameters below!\n",
    "#lasso_results = brute_force(df_scaled, \n",
    "#                        'Salary', \n",
    "#                        predictors, \n",
    "#                        Lasso, \n",
    "#                        alpha_list=np.logspace(-10, 4, 10), \n",
    "#                        degree_list = [2,  3, 4],\n",
    "#                        max_num_features_to_try = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.3470978\n",
      "Best predictors =  ['AtBat', 'Walks', 'Years', 'CHits', 'CRBI']\n",
      "Input dimension =  126\n",
      "Optimal degree polynomial =  4\n",
      "Optimal regularization value =  0.00599484250319\n"
     ]
    }
   ],
   "source": [
    "#print_essential_results(lasso_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.839877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td> 0.839877</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual  predicted\n",
       "actual     1.000000   0.839877\n",
       "predicted  0.839877   1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'actual' : lasso_results[8], 'predicted' : lasso_results[1].predict(lasso_results[7])}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Introduce a new parameter 'max_num_features_to_try', so as to limit the number of features this function will\n",
    "#use as a argument into combinations\n",
    "\n",
    "def brute_force_SVR(data, target_variable, predictors, C_list = [1.0], gamma_list = [1.0],\n",
    "                max_num_features_to_try = 3):\n",
    "    ''' brute_force is a simple function designed to:\n",
    "    test every combination of predictors submitted in the predictors argument\n",
    "    test all degrees of polynomial as submitted in the degree_list argument\n",
    "    test a number of regularization parameters as submitted in the alpha_list argument\n",
    "    \n",
    "    model is the algorithm to be tested\n",
    "     '''\n",
    "    min_mse = 1e99\n",
    "    test_size_split = 0.5\n",
    "\n",
    "    #search over every combination of the predictors - using the itertools functionality\n",
    "    for i in xrange(1, max_num_features_to_try + 1):\n",
    "        #it's not a bad idea to put an indicator of progress into the code\n",
    "        print '.',\n",
    "        \n",
    "        #build and test a model for each combination of predictors\n",
    "        for j in combinations(predictors, i):\n",
    "            \n",
    "            test_predictors = list(j)\n",
    "            \n",
    "            #use train test split to get the training and test datasets, according to the parameter test_size_split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data[test_predictors], \\\n",
    "                                                    data[target_variable], test_size=test_size_split, random_state=42)\n",
    "            \n",
    "            \n",
    "            ########-------------------------------\n",
    "            \n",
    "            ########TYPE IN EXERCISE\n",
    "            \n",
    "            \n",
    "            ########-------------------------------\n",
    "                    \n",
    "                    #measure the mean squared error of the test set\n",
    "                    mse = mean_squared_error(y_hat, y_test)\n",
    "                    \n",
    "                    #remember ALL information for the minimum\n",
    "                    if mse < min_mse:\n",
    "                        min_mse = mse\n",
    "                        min_clf = clf\n",
    "                        min_predictors = test_predictors\n",
    "                        min_C = C_param\n",
    "                        min_gamma = gamma_param\n",
    "                        #unless you cannot afford to do this, it is always a good idea to remember the train, test\n",
    "                        #datasets actually used to build your model\n",
    "                        min_X_train = X_train\n",
    "                        min_y_train = y_train\n",
    "                        min_X_test = X_test\n",
    "                        min_y_test = y_test\n",
    "                        input_dimension = X_train.shape[1]\n",
    "                    \n",
    "    #return a tuple for the minimum model and parameters\n",
    "    return (min_mse, min_clf, min_predictors, min_C, min_gamma, \n",
    "            min_X_train, min_y_train, min_X_test, min_y_test, input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . "
     ]
    }
   ],
   "source": [
    "#svr_results = brute_force_SVR(df_scaled, \n",
    "#                            'Salary', \n",
    "#                            predictors,  \n",
    "#                            C_list = [100.0, 500.0, 750.0], \n",
    "#                            gamma_list = [0.025, 0.05, 0.1],\n",
    "#                            max_num_features_to_try = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.3671368\n",
      "Best predictors =  ['AtBat', 'Walks', 'Years', 'CRBI', 'League']\n",
      "Input dimension =  5\n",
      "Optimal degree polynomial =  500.0\n",
      "Optimal regularization value =  0.05\n"
     ]
    }
   ],
   "source": [
    "#print_essential_results(svr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td>0.832005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual  predicted\n",
       "actual     1.000000   0.832005\n",
       "predicted  0.832005   1.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame({'actual' : svr_results[8], 'predicted' : svr_results[1].predict(svr_results[7])}).corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
