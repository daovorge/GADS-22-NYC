#Lesson 16 Recommendation Systems
###July 27th 2015

###Objectives for this class:
 * To define the Bayesian approach to A/B Testing
 * To identify and explore the Beta Distribution
 * To define and give an example of iterative Bayes
 * To list the competing priorities for editors monitoring 2 instant headlines
 * To define the Anscombe boundary, and determine that this is one solution to decision making that balances priorities
 
###Class Agenda
 - Class Open
  * Check in 
  * Review objectives
 - Small group exercise - class quiz on Bayes Formula
 - A/B Testing - Core concepts - Slides - Mark
 - Beta Distribution - iPython notebook - Mark & Class
 - Iterative Bayes - iPython notebook - Mark & Class
 - LAB: Amazon Resellers - Coding exercise - Class
 - Class Close
  * Check in
  * Class to pause around 9.15pm for the Exit ticket
  * Wrap up
 
 
### Term Project
  Answer the following questions:
  1. What is your topic? 
  2. Can you phrase your topic in the form of a question that you hope to answer?
  3. What do you plan to use as your source of data? 
  4. Do you have a sense for how large your dataset is? 
  5. Any other characteristics you know of?
  6. What tools or topics do you hope to learn and demonstrate by the end, or in other words, what are your learning objectives?


###Additional Resources
* [Bayesian Headline Testing Post No. 1](http://jeroenjanssens.com/2013/08/18/bayesian-headline-testing-at-visual-revenue.html)
* [Bayesian Headline Testing Post No. 2](http://developers.lyst.com/data/2014/05/10/bayesian-ab-testing/)
* [Bayesian Headline Testing Post No. 3](http://www.bayesianwitch.com/blog/2014/bayesian_ab_test.html)
* [A nice presentation about Naive Bayes](http://cis.poly.edu/~mleung/FRE7851/f07/naiveBayesianClassifier.pdf)
* [A fun post about Bayes](https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)
* [Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)
* [Naive Bayes Test Classification](http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html)
* Beaware of the linkedin Data Science group - plenty of blogs, discussion and job postings
* [Data Science Central](http://www.datasciencecentral.com/) For discussions, conferences, jobs, etc
* [Andrew Ng's coursera course](https://www.coursera.org/learn/machine-learning/home/info), which is a great machine learning course. The notation I have used matches his. His course used Octave (like matlab), so unless you are dead keen to learn this, you can ignore the programming exercises. The course is a little mathematical at times, but overall he presents great videos about gradient descent, and linear models.

* Books

* Pattern Recognition and Machine Learning by Christophter Bishop
 
* A good statistics book: Mathematical Statistics and Data Analysis by John A. Rice

* Meetups

* Courses
