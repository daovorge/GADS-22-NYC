{"nbformat_minor": 0, "nbformat": 4, "cells": [{"execution_count": 14, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import matplotlib as mpl\n", "from mpl_toolkits.mplot3d import axes3d\n", "%matplotlib inline\n", "from sklearn import linear_model\n", "from sklearn.preprocessing import PolynomialFeatures\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.metrics import mean_squared_error\n", "from matplotlib import cm"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 3, "cell_type": "code", "source": ["mpl.style.use('ggplot')"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["##Let's define some simple non-linear functions"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": ["#A simple sinusoid\n", "def f(x):\n", "    return np.sin(2.0 * np.pi * x)\n", "\n", "#A quadratic\n", "def fb(x):\n", "    return -np.power(x, 2)\n", "\n", "#A complex mixture of sinusoids\n", "def fc(x):\n", "    return np.sin(2.0 * np.pi * x) + np.cos(6.0 * np.pi * x) + np.sin(16 * np.pi * x)"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 5, "cell_type": "code", "source": ["#seed the random number generator so that we can produce repeatable results\n", "np.random.seed(9)\n", "\n", "#m is the number of training examples\n", "m = 100\n", "\n", "#evenly spaced points\n", "x_plot = np.linspace(0, 1, m)\n", "\n", "#randomly spaced points\n", "X = np.random.uniform(0, 1, size = m)[:, np.newaxis] #same as x.reshape(n_samples, 1)\n", "\n", "#obtain randomly spaced y values and add some gaussian noise\n", "y = f(X) + np.random.normal(scale=0.3, size = m)[:, np.newaxis]\n", "yb = fb(X) + np.random.normal(scale=0.1, size = m)[:, np.newaxis]\n", "yc = fc(X) + np.random.normal(scale=0.3, size = m)[:, np.newaxis]\n", "\n", "#these are just to help us visualize what's going on in the x-axis\n", "r1 = np.ones(m) * -1.5\n", "r2 = np.ones(m) * -2.0"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": ["#Plotting\n", "fig = plt.figure(figsize=(10,10))\n", "\n", "#3 rows, 1 col, plot 1\n", "ax = plt.subplot(311)\n", "\n", "#plot the known function\n", "ax.plot(x_plot, fb(x_plot), 'g', label='Known function')\n", "\n", "ax.set_xlim(0,1)\n", "ax.set_ylim(-2,2)\n", "ax.set_xlabel('X')\n", "ax.set_ylabel('y')\n", "ax.set_title('Quadratic Function')\n", "\n", "#plot the noisey y points, dervied from the function\n", "ax.scatter(X, yb, color = 'red', label=\"Noisey Training Points\")\n", "ax.legend()\n", "\n", "#3 rows, 1 col, plot 2\n", "ax = plt.subplot(312)\n", "\n", "#plot the known function\n", "ax.plot(x_plot, f(x_plot), 'g', label='Known function')\n", "\n", "ax.set_xlim(0,1)\n", "ax.set_ylim(-2,2)\n", "ax.set_xlabel('X')\n", "ax.set_ylabel('y')\n", "ax.set_title('Simple Sinusoid')\n", "\n", "#for curiosity observe the randomly spaced points and the evenly spaced points on the x axis\n", "ax.scatter(X, r1)\n", "ax.scatter(x_plot, r2)\n", "\n", "#plot the noisey y points, dervied from the function\n", "ax.scatter(X, y, color = 'red', label=\"Noisey Training Points\")\n", "ax.legend()\n", "\n", "\n", "\n", "#3 rows, 1 col, plot 3\n", "ax = plt.subplot(313)\n", "\n", "#plot the known function\n", "ax.plot(x_plot, fc(x_plot), 'g', label='Known function')\n", "\n", "ax.set_xlim(0,1)\n", "ax.set_ylim(-3,3)\n", "ax.set_xlabel('X')\n", "ax.set_ylabel('y')\n", "ax.set_title('Complex Sinusoid')\n", "\n", "\n", "#plot the noisey y points, dervied from the function\n", "ax.scatter(X, yc, color = 'red', label=\"Noisey Training Points\")\n", "ax.legend()\n", "\n", "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=0.5)"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["##Let's create both linear and non-linear regression models for the noisey training points"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": ["#Fit a model to the simple sinusoid\n", "lin_clf = linear_model.LinearRegression(fit_intercept=True)\n", "lin_clf.fit(X, y)\n", "\n", "#Fit a model to the quadratic data\n", "linb_clf = linear_model.LinearRegression(fit_intercept=True)\n", "linb_clf.fit(X, yb)\n", "\n", "#Fit a model to the complex sinusoid\n", "linc_clf = linear_model.LinearRegression(fit_intercept=True)\n", "linc_clf.fit(X, yc)\n", "\n", "fig = plt.figure(figsize=(15, 15))\n", "\n", "\n", "\n", "#----------QUADRATIC------------\n", "#3 rows, 1 col, first plot\n", "ax = plt.subplot(311)\n", "ax.set_xlabel('X')\n", "ax.set_ylabel('y')\n", "ax.set_title('Quadratic Function')\n", "#make predictions using the model built on the quadratic data and plot\n", "ax.plot(X, linb_clf.predict(X), label=\"Linear Model\")\n", "#plot the quadratic data\n", "ax.scatter(X, yb, label=\"Training Points\")\n", "\n", "#now fit a degree 2 (quadratic) polynomial model\n", "degree = 2\n", "nlb_clf = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n", "nlb_clf.fit(X, yb)\n", "#in order to plot as a line the points need to be in order\n", "Xpb = np.sort(X[:,0])\n", "#Xpb needs to be re-shaped again in order to work in the model\n", "ax.plot(Xpb, nlb_clf.predict(Xpb[:, np.newaxis]), color='magenta', label=\"Polynomial Model\")\n", "ax.legend()\n", "\n", "\n", "#----------SIMPLE SINUSOID------------\n", "#3 rows, 1 col, second plot\n", "ax1 = plt.subplot(312)\n", "ax1.set_xlabel('X')\n", "ax1.set_ylabel('y')\n", "ax1.set_title('Simple Sinusoid')\n", "ax1.plot(X, lin_clf.predict(X), label=\"Linear Model\")\n", "ax1.scatter(X, y, label=\"Training Points\")\n", "\n", "#fit a cubic (degree 3) polynomial model\n", "degree = 3\n", "nl_clf = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n", "nl_clf.fit(X, y)\n", "Xp = np.sort(X[:,0])\n", "ax1.plot(Xp, nl_clf.predict(Xp[:, np.newaxis]), color='magenta', label=\"Polynomial Model\")\n", "ax1.legend()\n", "\n", "\n", "#----------COMPLEX SINUSOID------------\n", "#3 rows, 1 col, third plot\n", "ax2 = plt.subplot(313)\n", "ax2.set_xlabel('X')\n", "ax2.set_ylabel('y')\n", "ax2.set_title('Complex Sinusoid')\n", "ax2.plot(X, linc_clf.predict(X), label=\"Linear Model\")\n", "ax2.scatter(X, yc, label=\"Training Points\")\n", "\n", "#fit a massively complex polynomial of degree 50!\n", "degree = 50\n", "nlb_clf = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n", "nlb_clf.fit(X, yc)\n", "Xpc = np.sort(X[:,0])\n", "ax2.plot(Xp, nlb_clf.predict(Xp[:, np.newaxis]), color='magenta', label=\"Polynomial Model\")\n", "ax2.plot(x_plot, fc(x_plot), label=\"Known Function\")\n", "ax2.legend()\n", "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=0.5)"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["#Now let's work in 2-dimensional feature space\n", "##$h(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2}$"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": ["#Define a 'known' function\n", "def fd(x1, x2):\n", "    return np.sin(2.0 * np.pi * x1) + np.cos(2.0 * np.pi * x2)"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["##At a pinch we can still plot the results"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": ["#create the canvas\n", "fig = plt.figure(figsize=(15,15))\n", "\n", "#this will be a 3 dimensional plot\n", "ax = fig.add_subplot(1, 1, 1, projection='3d')\n", "\n", "\n", "#-------------FIRSTLY CREATE A 3D SURFACE PLOT OF THE KNOWN FUNCTION-------------\n", "m=50\n", "X1a = np.linspace(0, 1, m)\n", "X2a = np.linspace(0, 1, m)\n", "#ynl = fd(X1a, X2a)\n", "\n", "X1, X2 = np.meshgrid(X1a, X2a)\n", "\n", "Z=[]\n", "for i in range(m):\n", "    for j in range(m):\n", "        Z.append(fd(X1[i][j], X2[i][j]))\n", "\n", "Z = np.array(Z)\n", "Z = Z.reshape(m, m)\n", "\n", "ax.elev=10.0\n", "ax.azim=45.0\n", "\n", "ax.set_title(\"Surface Plot of Known Function with Linear Model Predictions\")\n", "ax.set_xlabel(\"X1\")\n", "ax.set_ylabel(\"X2\")\n", "ax.set_zlabel(\"Y\")\n", "surf = ax.plot_surface(X1, X2, Z, rstride=1, cstride=1, \\\n", "                       cmap=cm.coolwarm, linewidth=0, antialiased=True, alpha=0.3)\n", "\n", "#-------------NOW BUILD LINEAR MODELS FOR LINEAR AND NON-LINEAR REGRESSION PREDICTIONS------------\n", "#-------------To avoid difficult to understand reshaping, use the pandas dataframe data structure\n", "T1 = []\n", "T2 = []\n", "\n", "#Create a meshgrid as two columns for a dataframe\n", "for i in range(m):\n", "    for j in range(m):\n", "        T1.append(X1a[i])\n", "        T2.append(X2a[j])\n", "\n", "#Create the dictionary\n", "data = {'T1':T1, 'T2':T2}\n", "\n", "#and convert to a dataframe\n", "df = pd.DataFrame(data)\n", "\n", "#create the y column\n", "df['y'] = fd(df.T1, df.T2)\n", "\n", "#create and fit the dataframe data to a linear model - creating a 2-dimensional plane\n", "nlin_clf = linear_model.LinearRegression(fit_intercept=True)\n", "nlin_clf.fit(df[['T1', 'T2']], df['y'])\n", "#plot the predictions from the model\n", "ax.scatter(df['T1'], df['T2'], nlin_clf.predict(df[['T1', 'T2']]), \\\n", "           alpha = 0.1, color = 'black', marker = 'x', label=\"Linear Regression Model\")\n", "\n", "#now create and fit a non-linear regression model using a polynomial of degree 50!\n", "nlinb_clf = linear_model.LinearRegression(fit_intercept=True)\n", "degree = 50\n", "nlinb_clf = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n", "nlinb_clf.fit(df[['T1', 'T2']], df['y'])\n", "#plot the predictions from the model\n", "ax.scatter(df['T1'], df['T2'], nlinb_clf.predict(df[['T1', 'T2']]), \\\n", "           alpha = 0.25, color = 'black', marker = '.', label=\"Non-linear Regression Model\")\n", "ax.legend()"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 28, "cell_type": "code", "source": ["mpl.style.use('ggplot')\n", "np.random.seed(9)\n", "m = 100\n", "\n", "#Create m points from our sinuisoidal function\n", "X = np.random.uniform(0, 1, size=m)[:, np.newaxis] \n", "y = f(X) + np.random.normal(scale=0.3, size=m)[:, np.newaxis]\n", "\n", "#Now use train_test_split to partition the dataset\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8)\n", "\n", "max_degree = 10\n", "training_error = np.zeros(max_degree)\n", "testing_error = np.zeros(max_degree)\n", "\n", "#fit models from degree 0 to degree 9\n", "#use the training set to fit the model\n", "#but collect the validation errors for both the training and validation sets\n", "for degree in xrange(max_degree):\n", "    clf = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n", "    clf.fit(X_train, y_train)\n", "    training_error[degree] = mean_squared_error(y_train, clf.predict(X_train))\n", "    testing_error[degree] = mean_squared_error(y_test, clf.predict(X_test))\n", "\n", "\n", "fig = plt.figure(figsize=(15, 5))\n", "ax = plt.subplot(111)\n", "ax.plot(np.arange(10), training_error, 'g', label='Training Error')\n", "ax.plot(np.arange(10), testing_error, 'r', label='Validation Error')\n", "ax.set_title(\"Optimum Model Size\")\n", "ax.set_yscale('Log')\n", "ax.set_xlabel('Degree')\n", "ax.set_ylabel('Log(MSE)')\n", "ax.legend(loc='lower left')"], "outputs": [], "metadata": {"collapsed": false}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.9", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}