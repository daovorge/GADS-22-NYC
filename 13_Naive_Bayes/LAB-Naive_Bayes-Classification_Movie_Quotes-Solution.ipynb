{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Naive Bayes Classification - Predicting Movie Quotes\n",
    "=====\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##Count Vectorization\n",
    "###Obtaining word frequencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = Math is great\n",
      "1 = Math is really great\n",
      "2 = Exciting exciting Math\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(text):\n",
    "    print \"{:d} = {:s}\".format(i, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngr = (1, 1)\n",
    "myCVa = CountVectorizer(ngram_range = ngr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####As per usual you fit the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCVa.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf_text = myCVa.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####The use the transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 = exciting\n",
      " 1 = great\n",
      " 2 = is\n",
      " 3 = math\n",
      " 4 = really\n"
     ]
    }
   ],
   "source": [
    "for i, fn in enumerate(myCVa.get_feature_names()):\n",
    "    print \"{:2d} = {:s}\".format(i, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####The transform method returns a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "print transf_text\n",
    "#(A, B)  C\n",
    "#A refers to the text number. There were 3 sentences so you would expect 0, 1, 2\n",
    "#The 0 text is \"Math is great\"\n",
    "#B refers to the feature. There are 5 features so you would expect 0, 1, 2, 3, 4\n",
    "#The 1 feature is 'great', 2 is 'is', 3 is 'math'\n",
    "#C is the frequency of the word in the text\n",
    "#There are 2 instances of 'exciting' in the 3rd sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Which you can visualize as a dense matrix\n",
    "#####There are 3 sentences and 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0]\n",
      " [0 1 1 1 1]\n",
      " [2 0 0 1 0]]\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "print transf_text.todense()\n",
    "print transf_text.todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##What is an ngram?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Set the begining n-gram length to 1\n",
    "#####Set the end n-gram length to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngr = (1, 2)\n",
    "myCVb = CountVectorizer(ngram_range = ngr)\n",
    "myCVb.fit(text)\n",
    "transformed_text = myCVb.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Now look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 = exciting\n",
      " 1 = exciting exciting\n",
      " 2 = exciting math\n",
      " 3 = great\n",
      " 4 = is\n",
      " 5 = is great\n",
      " 6 = is really\n",
      " 7 = math\n",
      " 8 = math is\n",
      " 9 = really\n",
      "10 = really great\n"
     ]
    }
   ],
   "source": [
    "for i, fn in enumerate(myCVb.get_feature_names()):\n",
    "    print \"{:2d} = {:s}\".format(i, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = Math is great\n",
      "1 = Math is really great\n",
      "2 = Exciting exciting Math\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(text):\n",
    "    print \"{:d} = {:s}\".format(i, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "print transformed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 11)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print transformed_text.shape\n",
    "print type(transformed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 11)\n",
      "[[0 0 0 1 1 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 1 1 1 1]\n",
      " [2 1 1 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dense_array = transformed_text.toarray()\n",
    "print dense_array.shape\n",
    "print dense_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Understanding the sparse array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 7\n",
      "0 8\n",
      "1 3\n",
      "1 4\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "2 1\n",
      "2 2\n",
      "2 7\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(3):\n",
    "    for j in xrange(11):\n",
    "        if dense_array[i][j] == 1:\n",
    "            print i,j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Questions:\n",
    "===\n",
    "1. What does 1 10 represent?\n",
    " \n",
    "2. What does 0 8 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Movie Database\n",
    "=====\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "critics_data = pd.read_csv(\"/Users/mrgholt/GADS-22-NYC/Datasets/rt_critics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'> critic\n",
      "<type 'str'> fresh\n",
      "<type 'str'> imdb\n",
      "<type 'str'> publication\n",
      "<type 'str'> quote\n",
      "<type 'str'> review_date\n",
      "<type 'str'> rtid\n",
      "<type 'str'> title\n"
     ]
    }
   ],
   "source": [
    "for i in critics_data.columns:\n",
    "    print type(i), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709        Time Out   \n",
       "1     Richard Corliss  fresh  114709   TIME Magazine   \n",
       "2         David Ansen  fresh  114709        Newsweek   \n",
       "3       Leonard Klady  fresh  114709         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader   \n",
       "\n",
       "                                               quote review_date  rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO Determine what values 'fresh' can take in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fresh', 'rotten', 'none']\n"
     ]
    }
   ],
   "source": [
    "terms = []\n",
    "for t in critics_data.fresh:\n",
    "    if t not in terms:\n",
    "        terms.append(t)\n",
    "print terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14072 entries, 0 to 14071\n",
      "Data columns (total 8 columns):\n",
      "critic         13382 non-null object\n",
      "fresh          14072 non-null object\n",
      "imdb           14072 non-null float64\n",
      "publication    14072 non-null object\n",
      "quote          14072 non-null object\n",
      "review_date    14072 non-null object\n",
      "rtid           14072 non-null float64\n",
      "title          14072 non-null object\n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 989.4+ KB\n"
     ]
    }
   ],
   "source": [
    "critics_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc = critics_data[['fresh', 'quote']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14072 entries, 0 to 14071\n",
      "Data columns (total 2 columns):\n",
      "fresh    14072 non-null object\n",
      "quote    14072 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 329.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fresh', 'rotten', 'none']\n"
     ]
    }
   ],
   "source": [
    "terms = []\n",
    "for t in dc.fresh:\n",
    "    if t not in terms:\n",
    "        terms.append(t)\n",
    "print terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Create a new data frame that contains only records where 'fresh' has values 'fresh' and 'rotten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdc = dc[(dc.fresh == 'rotten') | (dc.fresh == 'fresh')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fresh', 'rotten']\n"
     ]
    }
   ],
   "source": [
    "terms = []\n",
    "for t in fdc.fresh:\n",
    "    if t not in terms:\n",
    "        terms.append(t)\n",
    "print terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14049 entries, 0 to 14071\n",
      "Data columns (total 2 columns):\n",
      "fresh    14049 non-null object\n",
      "quote    14049 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 329.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fdc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Create a 'y' variable which is the factorization of the 'fresh' column, so 'fresh' gets converted to 0 (or 1)\n",
    "#and 'rotten' gets converted to 1 (or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.factorize(fdc.fresh)[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: How many of each class ('fresh' and 'rotten') do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n",
      "5436\n"
     ]
    }
   ],
   "source": [
    "print fdc.fresh[fdc.fresh=='fresh'].count()\n",
    "print fdc.fresh[fdc.fresh=='rotten'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    So ingenious in concept, design and execution ...\n",
      "1                    The year's most inventive comedy.\n",
      "2    A winning animated feature that has something ...\n",
      "3    The film sports a provocative and appealing st...\n",
      "4    An entertaining computer-generated, hyperreali...\n",
      "Name: quote, dtype: object \n",
      "\n",
      "19    A gloomy special-effects extravaganza filled w...\n",
      "22                               Mediocre, regrettably.\n",
      "25    The movie is too pat and practiced to really b...\n",
      "27    Never escapes the queasy aura of Melrose Place...\n",
      "29    You want the movie to stomp and rejoice and cr...\n",
      "Name: quote, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print fdc.quote[fdc.fresh == 'fresh'][0:5], '\\n'\n",
    "print fdc.quote[fdc.fresh == 'rotten'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Now using CountVectorizer fit and transform the quotes, start using a n-gram size of (1-1)\n",
    "#hint: you can fit and transform in one hit using \"fit_transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crV = CountVectorizer(ngram_range = (1, 1))\n",
    "X = crV.fit_transform(fdc.quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14049, 21530) (14049,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is an example of quote that is associated with the 'fresh' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh\n",
      "Offers above-average pyrotechnics, a body count that steadily mounts, and plenty of hand-to-hand combat.\n"
     ]
    }
   ],
   "source": [
    "test_quote = fdc.quote[fdc.fresh == 'fresh'][50:51].values[0]\n",
    "print fdc.fresh[fdc.fresh == 'fresh'][50:51].values[0]\n",
    "print test_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ...and here is an example of a quote that is associated with the 'rotten' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After coming out gangbusters in its first and finest hour, the 180-minute movie loses all its chips in the remaining two.\n"
     ]
    }
   ],
   "source": [
    "test_quote = fdc.quote[fdc.fresh == 'rotten'][50:51].values[0]\n",
    "fdc.fresh[fdc.fresh == 'rotten'][50:51].values[0]\n",
    "print test_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Using train test split fit a mulitnomialNB model and a BernoulliNB model to the training data\n",
    "#TODO: What accuracy to do you get on the test set for each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777113578138\n"
     ]
    }
   ],
   "source": [
    "clfMN = MultinomialNB().fit(xtrain, ytrain)\n",
    "print clfMN.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764588670652\n"
     ]
    }
   ],
   "source": [
    "clfB = BernoulliNB().fit(xtrain, ytrain)\n",
    "print clfB.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: now test some of your own review language in a very short sentence and see if your review is predicted as\n",
    "#fresh or rotten\n",
    "#If you want to use the helper function below\n",
    "#Remember: use the count vectorizer transform method to convert your quote into a sparse array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def report_results(clf, my_sparse, my_review):\n",
    "    #get the probabilities from the model\n",
    "    res_prob = clf.predict_proba(my_sparse).ravel()\n",
    "    \n",
    "    #set up the correct output string\n",
    "    if clf.predict(my_sparse) == 0:\n",
    "        result = \"fresh\"\n",
    "        \n",
    "    else:\n",
    "        result = \"rotten\"\n",
    "    \n",
    "    #print the result making sure the correct probability is used\n",
    "    print \"Your review:\\n '\", my_review, \"'\", \"\\n\\nhas a {:5.2f}% chance of being classified in the '{:s}' class\".\\\n",
    "    format(res_prob[clf.predict(my_sparse)][0] * 100.0, result)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Here are some test quotes to start you off testing your models\n",
    "#####Try individual words, try phrases - explore the space a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_quotes = [\"This was an awesome movie\", \\\n",
    "              \"This movie was so self indulgant that it really couldn't get over itself\", \\\n",
    "              \"So ingenious in concept\", \\\n",
    "              \"A gloomy special-effects extravaganza filled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your review:\n",
      " ' This was an awesome movie ' \n",
      "\n",
      "has a 67.55% chance of being classified in the 'fresh' class\n",
      "\n",
      "\n",
      "Your review:\n",
      " ' This movie was so self indulgant that it really couldn't get over itself ' \n",
      "\n",
      "has a 92.19% chance of being classified in the 'rotten' class\n",
      "\n",
      "\n",
      "Your review:\n",
      " ' So ingenious in concept ' \n",
      "\n",
      "has a 64.56% chance of being classified in the 'fresh' class\n",
      "\n",
      "\n",
      "Your review:\n",
      " ' A gloomy special-effects extravaganza filled ' \n",
      "\n",
      "has a 77.74% chance of being classified in the 'rotten' class\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_quote in test_quotes:\n",
    "    my_sparse_matrix = crV.transform([test_quote])\n",
    "    report_results(clfMN, my_sparse_matrix, test_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: print out a pd crosstab for the predictors using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1\n",
       "Actual              \n",
       "0          1861  290\n",
       "1           493  869"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ytest, clfMN.predict(xtest), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1895</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>571</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1\n",
       "Actual              \n",
       "0          1895  256\n",
       "1           571  791"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ytest, clfB.predict(xtest), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Questions:\n",
    "===\n",
    "1. n-gram settings gives the best results - 1, 2, or 3?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
