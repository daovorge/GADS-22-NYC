{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = fetch_covtype(random_state=11, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Covertype dataset\n",
    "\n",
    "####580,000+ examples of data obtained from 30 x 30 meter patches of US Forest\n",
    "####The aim of collecting the data was to predict the dominant species of tree for each patch (covertype)\n",
    "####7 species of tree have been labelled to create a 7 class prediction problem\n",
    "####From each patch a total of 54 features have been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest covertype dataset.\n",
      "\n",
      "A classic dataset for classification benchmarks, featuring categorical and\n",
      "real-valued features.\n",
      "\n",
      "The dataset page is available from UCI Machine Learning Repository\n",
      "\n",
      "    http://archive.ics.uci.edu/ml/datasets/Covertype\n",
      "\n",
      "Courtesy of Jock A. Blackard and Colorado State University.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "covertypes = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_confusion_matrix(y_test, y_hat, names):\n",
    "    '''This function uses the pd.crosstab function to create a confusion matrix:\n",
    "    predictions are the predictions from the predictive mode\n",
    "    y are the known class labels\n",
    "    names are the names of the features used in the model'''\n",
    "    \n",
    "    cf = pd.crosstab(y_test, y_hat)\n",
    "    cf.columns = names\n",
    "    cf.index = names\n",
    "    cf.columns.name = 'Prediction'\n",
    "    cf.index.name = 'Actual'\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581012, 54)\n"
     ]
    }
   ],
   "source": [
    "size = data.data\n",
    "print size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_shuffle(X, y):\n",
    "    Xa = X.copy()\n",
    "    ya = y.copy()\n",
    "    \n",
    "    for i in xrange(100000):\n",
    "        n1 = randint(0, 13999)\n",
    "        n2 = randint(0, 13999)\n",
    "        \n",
    "        tempx = Xa[n1, :].copy()\n",
    "        tempy = ya[n1].copy()\n",
    "\n",
    "        Xa[n1, :] = Xa[n2, :].copy()\n",
    "        ya[n1] = ya[n2].copy()\n",
    "\n",
    "        Xa[n2, :] = tempx\n",
    "        ya[n2] = tempy\n",
    "    \n",
    "    return (Xa, ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class  1   2000\n",
      "class  2   2000\n",
      "class  3   2000\n",
      "class  4   2000\n",
      "class  5   2000\n",
      "class  6   2000\n",
      "class  7   2000\n",
      "\n",
      "\n",
      "\n",
      "shapes here (14000, 54) (14000, 1)\n",
      "class  1   2000\n",
      "class  2   2000\n",
      "class  3   2000\n",
      "class  4   2000\n",
      "class  5   2000\n",
      "class  6   2000\n",
      "class  7   2000\n"
     ]
    }
   ],
   "source": [
    "X1 = np.zeros((14000, 54))\n",
    "y1 = np.zeros((14000, 1))\n",
    "features = range(54)\n",
    "df1 = pd.DataFrame(data.data)\n",
    "df1[\"y\"] = data.target\n",
    "#df1[df1.y == 1][features][0:2000]\n",
    "for i in xrange(1, 8):\n",
    "    j = i-1\n",
    "    X1[j*2000:i*2000, :] = df1[df1.y == i][features][0:2000].values\n",
    "    y1[j*2000:i*2000, :] = i\n",
    "\n",
    "\n",
    "y1 = y1.ravel()\n",
    "td = {}\n",
    "for i in xrange(1, 8):\n",
    "    td[i] = 0\n",
    "for i in xrange(len(y1)):\n",
    "    td[y1[i]] += 1\n",
    "for i in xrange(1, 8):\n",
    "    print \"class \", i, \" \", td[i]\n",
    "print \"\\n\\n\"\n",
    "y1 = y1.reshape(y1.shape[0], 1)\n",
    "print \"shapes here\", X1.shape, y1.shape\n",
    "X2, y2 = my_shuffle(X1, y1)\n",
    "\n",
    "y2 = y2.ravel()\n",
    "td = {}\n",
    "for i in xrange(1, 8):\n",
    "    td[i] = 0\n",
    "for i in xrange(len(y2)):\n",
    "    td[y2[i]] += 1\n",
    "for i in xrange(1, 8):\n",
    "    print \"class \", i, \" \", td[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X2[0,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xs[0,0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Example Bagging\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Sklearn Bagging Classifier encompasses a number of the averaging methods\n",
    "###It has a comprehensive argument list:\n",
    "\n",
    "- base_estimator is the classifier you are going to use with bagging\n",
    "- n_estimators is the number of base estimators to use\n",
    "- max_samples is the number of samples to draw from the complete training set, each random sample is used to train one of the base estimators\n",
    "- max_features is the number of features to use from the complete training set\n",
    "- bootstrap, if True, indicates to the algorithm to draw with replacement (remember you replace after each sample draw)\n",
    "- bootstrap_features, if True, indicates to the algorithm to draw the features with replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Try the base classifier first\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mySSS = StratifiedShuffleSplit(y2, 1, test_size=0.5, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.71      0.64      0.67      1000\n",
      "        2.0       0.64      0.59      0.61      1000\n",
      "        3.0       0.76      0.68      0.72      1000\n",
      "        4.0       0.88      0.93      0.90      1000\n",
      "        5.0       0.80      0.91      0.85      1000\n",
      "        6.0       0.73      0.75      0.74      1000\n",
      "        7.0       0.90      0.95      0.92      1000\n",
      "\n",
      "avg / total       0.77      0.78      0.77      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfKNN = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfKNN.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = clfKNN.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####Now wrap the Bagging Classifier around the base classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795571428571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.71      0.66      0.68      1000\n",
      "        2.0       0.69      0.59      0.63      1000\n",
      "        3.0       0.80      0.69      0.75      1000\n",
      "        4.0       0.87      0.95      0.91      1000\n",
      "        5.0       0.80      0.93      0.86      1000\n",
      "        6.0       0.76      0.80      0.78      1000\n",
      "        7.0       0.91      0.95      0.93      1000\n",
      "\n",
      "avg / total       0.79      0.80      0.79      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfBag = BaggingClassifier(base_estimator = KNeighborsClassifier(n_neighbors = 1), n_estimators = 100, max_samples = 0.7,\\\n",
    "                          max_features = 0.7, random_state = 6, n_jobs = -1)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfBag.fit(X_train, y_train)\n",
    "\n",
    "    y_hat = clfBag.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Introducing cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790928571429\n",
      "0.00192857142857\n"
     ]
    }
   ],
   "source": [
    "clfBagB = BaggingClassifier(base_estimator = KNeighborsClassifier(n_neighbors = 1), n_estimators = 100, max_samples = 0.7,\\\n",
    "                          max_features = 0.7, random_state = 6, n_jobs = 1)\n",
    "scores = cross_val_score(clfBagB, Xs, y2, cv=2, scoring = 'accuracy', n_jobs = -1)\n",
    "print np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Patches Example\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Sklearn Ensemble Tree or Patches Classifiers have a number of important arguments\n",
    "\n",
    "- max_features\n",
    "- min_samples_leaf\n",
    "- bootstrap\n",
    "- n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833571428571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.74      0.73      0.74      1000\n",
      "        2.0       0.75      0.63      0.68      1000\n",
      "        3.0       0.85      0.78      0.81      1000\n",
      "        4.0       0.92      0.96      0.94      1000\n",
      "        5.0       0.85      0.92      0.88      1000\n",
      "        6.0       0.80      0.85      0.83      1000\n",
      "        7.0       0.92      0.96      0.94      1000\n",
      "\n",
      "avg / total       0.83      0.83      0.83      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(n_estimators = 100, n_jobs = -1,random_state = 11)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfRF.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = clfRF.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839285714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.75      0.73      0.74      1000\n",
      "        2.0       0.74      0.65      0.69      1000\n",
      "        3.0       0.85      0.78      0.82      1000\n",
      "        4.0       0.92      0.96      0.94      1000\n",
      "        5.0       0.86      0.93      0.89      1000\n",
      "        6.0       0.81      0.86      0.83      1000\n",
      "        7.0       0.93      0.95      0.94      1000\n",
      "\n",
      "avg / total       0.84      0.84      0.84      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfET = ExtraTreesClassifier(n_estimators = 150, n_jobs = -1,random_state = 11)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfET.fit(X_train, y_train)\n",
    "    y_hat = clfET.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Boosting Example\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.437142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.39      0.66      0.49      1000\n",
      "        2.0       0.28      0.14      0.19      1000\n",
      "        3.0       0.60      0.17      0.26      1000\n",
      "        4.0       0.46      0.12      0.18      1000\n",
      "        5.0       0.74      0.41      0.53      1000\n",
      "        6.0       0.32      0.85      0.46      1000\n",
      "        7.0       0.69      0.72      0.70      1000\n",
      "\n",
      "avg / total       0.50      0.44      0.40      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfAB = AdaBoostClassifier(n_estimators = 1000, random_state = 11)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfAB.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = clfAB.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GradientBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Gradient Boosting uses gradient descent\n",
    "####Gradient Boosting has the following arguments that need to be set carefully:\n",
    "- learning_rate\n",
    "- max_depth\n",
    "- subsample\n",
    "- min_samples_leaf\n",
    "- n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820714285714\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.74      0.70      0.72      1000\n",
      "        2.0       0.70      0.64      0.67      1000\n",
      "        3.0       0.81      0.77      0.79      1000\n",
      "        4.0       0.94      0.95      0.95      1000\n",
      "        5.0       0.84      0.91      0.87      1000\n",
      "        6.0       0.79      0.82      0.80      1000\n",
      "        7.0       0.91      0.95      0.93      1000\n",
      "\n",
      "avg / total       0.82      0.82      0.82      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfGB = GradientBoostingClassifier(n_estimators = 1000, random_state = 11)\n",
    "\n",
    "for train_index, test_index in mySSS:\n",
    "    X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]\n",
    "    \n",
    "    clfGB.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = clfGB.predict(X_test)\n",
    "    print accuracy_score(y_test, y_hat)\n",
    "    print classification_report(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[693, 188,   1,   0,  29,   6,  83],\n",
       "       [220, 603,  18,   0, 119,  31,   9],\n",
       "       [  1,  12, 755,  40,  16, 176,   0],\n",
       "       [  0,   0,  28, 955,   0,  17,   0],\n",
       "       [  7,  54,  12,   0, 914,  13,   0],\n",
       "       [  1,  19, 129,  18,  17, 816,   0],\n",
       "       [ 44,   1,   0,   0,   3,   0, 952]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>603</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>755</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1    2    3    4    5    6    7\n",
       "Actual                                      \n",
       "1          693  188    1    0   29    6   83\n",
       "2          220  603   18    0  119   31    9\n",
       "3            1   12  755   40   16  176    0\n",
       "4            0    0   28  955    0   17    0\n",
       "5            7   54   12    0  914   13    0\n",
       "6            1   19  129   18   17  816    0\n",
       "7           44    1    0    0    3    0  952"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.crosstab(y_test, clf.predict(X_test), rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>Spruce/Fir</th>\n",
       "      <th>Lodgepole Pine</th>\n",
       "      <th>Ponderosa Pine</th>\n",
       "      <th>Cottonwood/Willow</th>\n",
       "      <th>Aspen</th>\n",
       "      <th>Douglas-fir</th>\n",
       "      <th>Krummholz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Spruce/Fir</th>\n",
       "      <td>693</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lodgepole Pine</th>\n",
       "      <td>220</td>\n",
       "      <td>603</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ponderosa Pine</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>755</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cottonwood/Willow</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspen</th>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Douglas-fir</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Krummholz</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction         Spruce/Fir  Lodgepole Pine  Ponderosa Pine  \\\n",
       "Actual                                                          \n",
       "Spruce/Fir                693             188               1   \n",
       "Lodgepole Pine            220             603              18   \n",
       "Ponderosa Pine              1              12             755   \n",
       "Cottonwood/Willow           0               0              28   \n",
       "Aspen                       7              54              12   \n",
       "Douglas-fir                 1              19             129   \n",
       "Krummholz                  44               1               0   \n",
       "\n",
       "Prediction         Cottonwood/Willow  Aspen  Douglas-fir  Krummholz  \n",
       "Actual                                                               \n",
       "Spruce/Fir                         0     29            6         83  \n",
       "Lodgepole Pine                     0    119           31          9  \n",
       "Ponderosa Pine                    40     16          176          0  \n",
       "Cottonwood/Willow                955      0           17          0  \n",
       "Aspen                              0    914           13          0  \n",
       "Douglas-fir                       18     17          816          0  \n",
       "Krummholz                          0      3            0        952  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_confusion_matrix(y_test, clf.predict(X_test), covertypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
