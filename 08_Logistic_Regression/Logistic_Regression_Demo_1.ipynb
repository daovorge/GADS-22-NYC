{"nbformat_minor": 0, "nbformat": 4, "cells": [{"execution_count": 1, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import matplotlib as mpl\n", "mpl.style.use('ggplot')\n", "from sklearn.datasets import make_blobs\n", "from sklearn.preprocessing import PolynomialFeatures\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.cross_validation import train_test_split"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["---\n", "#Logistic Regression 1\n", "---"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": ["def decision_boundary(clf, x1lowlimit, x1highlimit, y1lowlimit, y1highlimit):\n", "    '''A very simplistic way of demonstrating the decision boundary'''\n", "    \n", "    #Get the coefficients from the parameteric model\n", "    ccs = clf.coef_.ravel()\n", "    \n", "    #Get the intercept value from the model\n", "    inter = clf.intercept_\n", "    \n", "    #Create some equally spaced points between 2 sets of limits that the user must provide\n", "    xx1 = np.linspace(x1lowlimit, x1highlimit, 400)\n", "    xx2 = np.linspace(x2lowlimit, x2highlimit, 400)\n", "    \n", "    y=[]\n", "    for x1 in xx1:\n", "        for x2 in xx2:\n", "            #The linear model will return close to zero near the decision boundary\n", "            if np.fabs((ccs[0]*x1) + (ccs[1] * x2) + inter) < 0.01:\n", "                \n", "                #append the pairs of points into the list y\n", "                y.append((x1,x2))\n", "    \n", "    \n", "    #return the list y, containing pairs of points that are close to the decision boundary\n", "    return y"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": ["#number of training examples\n", "m = 200\n", "\n", "#number of features\n", "N = 2\n", "\n", "#number of distinct clusters or groupings or 'blobs'\n", "num_blobs = 2\n", "\n", "#using sklearn's 'make_blobs' functionality to make some clusters of data\n", "#blobs also returns an array, y, which contains the identity of the blob each pair of points belongs to\n", "X, y = make_blobs(n_samples = m, n_features = N, centers=num_blobs, cluster_std=0.5, random_state=4)\n", "\n", "#Plot the blobs and color them for each blob\n", "fig = plt.figure(figsize = (7,7))\n", "ax = plt.subplot(111)\n", "ax.scatter(X[y == 1,0], X[y == 1,1], color='red', label='Blob 1, y = 1')\n", "ax.scatter(X[y == 0,0], X[y == 0,1], color='blue', label='Blob 0, y = 0')\n", "ax.set_title(\"Plot of Blobs\")\n", "ax.set_xlabel(\"x1\")\n", "ax.set_ylabel(\"x2\")\n", "ax.legend(loc='best')"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["---\n", "##Note that the above example illustrates the notion of Linear Separability in 2 dimensions\n", "---"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": ["#Fit a basic logistic regression model\n", "clf = LogisticRegression() \n", "clf.fit(X, y)\n", "\n", "#A confusion matrix indicates the results of classification\n", "#pd.crosstab returns a DataFrame\n", "cm = pd.crosstab(y, clf.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])\n", "cm"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": ["#Let's try and plot the decision boundary\n", "#Set the limits from the plot of the datapoints\n", "x1lowlimit = 7.5\n", "x1highlimit = 11\n", "x2lowlimit =-1\n", "x2highlimit = 6\n", "\n", "#Obtain the decision boundary points from the decision_boundary function\n", "db = decision_boundary(clf, x1lowlimit, x1highlimit, x2lowlimit, x2highlimit)\n", "\n", "#and plot in the usual way\n", "fig = plt.figure(figsize = (7,7))\n", "ax = plt.subplot(111)\n", "ax.scatter(X[y == 1,0], X[y == 1,1], color='red', label='Blob 1, y = 1')\n", "ax.scatter(X[y == 0,0], X[y == 0,1], color='blue', label='Blob 0, y = 0')\n", "db=np.array(db)\n", "ax.plot(db[:,0], db[:,1], 'k-', label='Decision Boundary')\n", "ax.set_title(\"Plot of Blobs\")\n", "ax.set_xlabel(\"x1\")\n", "ax.set_ylabel(\"x2\")\n", "ax.legend(loc='upper left')"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": ["#Now let's bring the blobs closer together and intermix them\n", "#These blobs are non-longer linearly separable\n", "m = 200\n", "N = 2\n", "num_blobs = 2\n", "\n", "#All we did was to increase the standard deviation of the blobs\n", "X, y = make_blobs(n_samples = m, n_features = N, centers=num_blobs, cluster_std=2.0, random_state=4)\n", "\n", "fig = plt.figure(figsize = (7,7))\n", "ax = plt.subplot(111)\n", "ax.scatter(X[y == 1,0], X[y == 1,1], color='red', label='Blob 1, y = 1')\n", "ax.scatter(X[y == 0,0], X[y == 0,1], color='blue', label='Blob 0, y = 0')\n", "ax.set_title(\"Plot of Blobs\")\n", "ax.set_xlabel(\"x1\")\n", "ax.set_ylabel(\"x2\")\n", "ax.legend(loc='best')"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 18, "cell_type": "code", "source": ["#Fit a Logistic Regression model again\n", "clf = LogisticRegression() \n", "clf.fit(X, y)\n", "\n", "#compute the confusion matrix\n", "cm = pd.crosstab(y, clf.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])\n", "cm"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 19, "cell_type": "code", "source": ["#Now let's look at the decision boundary\n", "#Using the plot above set the low and high limits for each dimension - needed for the decision_boundary function\n", "x1lowlimit = 2\n", "x1highlimit = 16\n", "x2lowlimit = -6\n", "x2highlimit = 12\n", "\n", "#Get some points near the decision boundary\n", "db = decision_boundary(clf, x1lowlimit, x1highlimit, x2lowlimit, x2highlimit)\n", "\n", "#Plot the points and the decision boundary\n", "fig = plt.figure(figsize = (7,7))\n", "ax = plt.subplot(111)\n", "ax.scatter(X[y == 1,0], X[y == 1,1], color='red', label='Blob 1, y = 1')\n", "ax.scatter(X[y == 0,0], X[y == 0,1], color='blue', label='Blob 0, y = 0')\n", "db=np.array(db)\n", "ax.plot(db[:,0], db[:,1], 'k-', label='Decision Boundary')\n", "ax.set_title(\"Plot of Blobs\")\n", "ax.set_xlabel(\"x1\")\n", "ax.set_ylabel(\"x2\")\n", "ax.legend(loc='upper left')"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["---\n", "##This is the best decision boundary that can be drawn to maximize the correct classification of the training data\n", "---"], "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.9", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}