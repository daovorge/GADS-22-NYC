#Lesson 15 Natural Language Processing
###July 22th 2015

###Objectives for this class:
 * To define and describe what Natural Language Processing (NLP) is
 * To conclude that NLP is a hard problem
 * To list and explain common techniques used in working with text
 * To define and explain the concept of Document Simiarity
 * To define and explain the concept of Latent Dirichlet Allocation
 
###Class Agenda
 - Class Open
  * Check in 
  * Review objectives
 - NLP - Core concepts - Slides - Mark
 - NLTK Library - demonstrating simple usage - iPython notebook - Mark & Class
 -  - iPython notebook - Mark & Class
 - LAB:  - Coding exercise - Class
 - Class Close
  * Check in
  * Class to pause around 9.25pm for the Exit ticket
  * Wrap up
 
 
### Term Project
  Answer the following questions:
  1. What is your topic? 
  2. Can you phrase your topic in the form of a question that you hope to answer?
  3. What do you plan to use as your source of data? 
  4. Do you have a sense for how large your dataset is? 
  5. Any other characteristics you know of?
  6. What tools or topics do you hope to learn and demonstrate by the end, or in other words, what are your learning objectives?


###Additional Resources
* [Bayesian Headline Testing Post No. 1](http://jeroenjanssens.com/2013/08/18/bayesian-headline-testing-at-visual-revenue.html)
* [Bayesian Headline Testing Post No. 2](http://developers.lyst.com/data/2014/05/10/bayesian-ab-testing/)
* [Bayesian Headline Testing Post No. 3](http://www.bayesianwitch.com/blog/2014/bayesian_ab_test.html)
* [A nice presentation about Naive Bayes](http://cis.poly.edu/~mleung/FRE7851/f07/naiveBayesianClassifier.pdf)
* [A fun post about Bayes](https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)
* [Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)
* [Naive Bayes Test Classification](http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html)
* Beaware of the linkedin Data Science group - plenty of blogs, discussion and job postings
* [Data Science Central](http://www.datasciencecentral.com/) For discussions, conferences, jobs, etc
* [Andrew Ng's coursera course](https://www.coursera.org/learn/machine-learning/home/info), which is a great machine learning course. The notation I have used matches his. His course used Octave (like matlab), so unless you are dead keen to learn this, you can ignore the programming exercises. The course is a little mathematical at times, but overall he presents great videos about gradient descent, and linear models.

* Books

* Pattern Recognition and Machine Learning by Christophter Bishop
 
* A good statistics book: Mathematical Statistics and Data Analysis by John A. Rice

* Meetups

* Courses
