{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Stochastic Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####SGDClassifier(), and SGDRegressor()\n",
    "- have both a .fit() method and a .partial_fit() method. The latter for use with batches\n",
    "- partial_fit() requires the declaration of the classes with the method. The algorithm needs to know in advance all the class codes that it expects to see during training\n",
    "- The loss paramters determines the modelling algorithm type. Loss can take the following values to allow for the following algorithms:\n",
    "1. loss - logistic regression\n",
    "2. hinge - linear support vector machine\n",
    "\n",
    "- SGDRegressor mimics linear regression using the squared_loss loss parameter. The huber loss transforms the squared loss into a linear loss over a certain distance, epsilon. It can also act as a linear SVM (regression) using the epsilon_insensitive loss, or squared_epsilon_insensitive (which penalizes outliers more)\n",
    "\n",
    "- Performance of different loss functions cannot be estimated a priori.\n",
    "\n",
    "- If doing classification and you need an estimation of class probabilities you will be limited in your choice to log or modified_huber only\n",
    "\n",
    "#####Other key Parameters:\n",
    "- n_iter: the number of iterations over the data\n",
    "- penalty: L1, L2, or elasticnet\n",
    "- alpha: regularization term. Higher means more regularization\n",
    "- L1 ratio: only used with elasticnet penalty to set the balance between L1 and L2 \n",
    "- learning_rate: Usually invscaling for regression. If you want to use invscaling for classification, set eta0 and power_t (invscaling = eta0/(t**power_t). With invscaling you can start with a lower learning rate, which is less than the optimal rate, but it will decrease more slowly\n",
    "- epsilon: only use if your loss is huber, epsilon_insensitive ro squared_epsilon_insensitive\n",
    "- shuffle: if True the algorithm will shuffle the training data order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch_20newsgroups - containing 11314 posts, with about 200 words in each post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Get the 20 news groups dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngd = fetch_20newsgroups(shuffle = True, remove = (\"headers\", \"footers\", \"quotes\"), random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "206.15980201520242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.shape((ngd.data))\n",
    "np.mean([len(text.split(' ')) for text in ngd.data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Using make_classification make a dataset with 10**7 samples and 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 5) (10000000,)\n"
     ]
    }
   ],
   "source": [
    "#To do - copy this cell and execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#Scalability with Volume\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Strategies to manage high volumes of data without loading it all into memory:\n",
    "- incrementally update the parameters of your algorithm until all the observations have been elaborated at least once\n",
    "- partial_fit() method which can be applied to a certain number of supervised and unsupervised algorithms\n",
    "- incremental learning: feed in chunks or batches of data to start fitting your model as soon as data arrives\n",
    "- incremental learning is about:\n",
    "1. Batch size - this is usually memory depdendent. In general the larger the better\n",
    "2. Data preprocessing - feature scaling can be extremely difficult, because ahead of time you don't know the range of your data. You either complete data collection and then re-scale, or you estimate the range of the features, scale on the fly and discard any obesrvations that exceed the anticipated range\n",
    "3. Number and passes through the data required (or not) - in general it is hard, if not possible to make more than one pass through the data. Data order is also very important. Stochastic Gradient Descent prefers shuffled dataa\n",
    "4. Validation and hyper-parameter tuning - more difficult than normal. Either validate in a progressive way, or hold out some observations from every chunk/batch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####read_csv allows iteration over the file by reading batches or chunks of 10000 observations (in this case)\n",
    "#####MinMaxScaler is used to range the data after the first batch becomes available, after this batches are trimmed, so no values exceed or fall below the min/max values set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Now run through the file by chunking the stream coming from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To do - copy this cell and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([0.65, 0.36, 0.49, 0.51, 0.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize = (15, 5))\n",
    "#ax = plt.subplot(111)\n",
    "#ax.plot(acc_list)\n",
    "#ax.set_title(\"SGD Logistic Regression Accuracy\")\n",
    "#ax.set_ylabel(\"Accuracy\")\n",
    "#ax.set_xlabel(\"Number of Training Samples (x10000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##Algorithm Choices offering Partial Fit\n",
    "\n",
    "###- MultinomialNB\n",
    "###- BernoulliNB\n",
    "###- SGDClassifier\n",
    "###- SGDRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- smaller batches tend to be slower, because usually the bottleneck for these things is disk access or data access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Handling data variability using hashing\n",
    "- hash functions map, in a deterministic way, using any input they receive, whether is be numerical or string input\n",
    "- they return an integer within a certain range\n",
    "- hashing is extremely fast and efficient\n",
    "\n",
    "#####Sparse matrices\n",
    "- as we have already seen, sparse matrices only hold non-zero values\n",
    "- a sparse matrix has a default value of zero\n",
    "\n",
    "####hashing therefore bounds every input, to a certain range, or position onto a corresponding sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To do - copy this cell and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To do - copy this cell and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To do - copy this cell and execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Try some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "new_text_A = [' A 2014 red Toyota Prius v Five with fewer than 14K miles. \\\n",
    "Powered by a reliable 1.8L four cylinder hybrid engine that averages 44mpg in the city and 40mpg on the highway.']\n",
    "\n",
    "new_text_B = ['There always seems to be something unusual about the political class.\\\n",
    "The GOP and Democrats are poles apart in ideology']\n",
    "\n",
    "new_text_C = ['Space, the final frontier. When one considers the number of start within the milky way galaxy, \\\n",
    "then it is hard not to conceive that there may be life out there']\n",
    "\n",
    "new_text_vector = my_hash.transform(new_text_C)\n",
    "\n",
    "yhat = clf.predict(new_text_vector)\n",
    "print ngd.target_names[yhat]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
